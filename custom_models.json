{
  "_README": {
    "description": "Model configurations optimized for NVIDIA RTX 5090 (32GB VRAM)",
    "usage": "Copy to your MCP server's conf/ directory or use as reference",
    "hardware_target": "NVIDIA RTX 5090 (32GB GDDR7) and similar GPUs"
  },
  "models": [
    {
      "model_name": "qwen2.5-coder:32b",
      "aliases": ["qwen-coder", "qwen-code", "coder"],
      "context_window": 131072,
      "max_output_tokens": 32768,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": false,
      "description": "Qwen 2.5 Coder 32B - Best local coding model, 92 languages",
      "intelligence_score": 18
    },
    {
      "model_name": "deepseek-r1:32b",
      "aliases": ["deepseek-r1", "deepseek", "r1", "reasoning"],
      "context_window": 131072,
      "max_output_tokens": 32768,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": false,
      "description": "DeepSeek-R1 32B - Best local reasoning model with chain-of-thought",
      "intelligence_score": 17
    },
    {
      "model_name": "qwen3:32b",
      "aliases": ["qwen3", "qwen", "local-qwen"],
      "context_window": 131072,
      "max_output_tokens": 32768,
      "supports_extended_thinking": true,
      "supports_json_mode": true,
      "supports_function_calling": false,
      "description": "Qwen3 32B - Latest generation general-purpose model",
      "intelligence_score": 17
    },
    {
      "model_name": "codellama:34b",
      "aliases": ["codellama", "code-llama"],
      "context_window": 16384,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_json_mode": false,
      "supports_function_calling": false,
      "description": "CodeLlama 34B - Meta's premier coding model",
      "intelligence_score": 15
    },
    {
      "model_name": "deepseek-coder:33b",
      "aliases": ["deepseek-coder", "ds-coder"],
      "context_window": 16384,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": false,
      "description": "DeepSeek Coder 33B - Strong coding model, 80+ languages",
      "intelligence_score": 15
    },
    {
      "model_name": "llama3.1:8b",
      "aliases": ["llama3.1", "llama-8b", "fast-search"],
      "context_window": 131072,
      "max_output_tokens": 32768,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "description": "Llama 3.1 8B - Fast model for web search with tool calling",
      "intelligence_score": 12
    },
    {
      "model_name": "mistral:7b",
      "aliases": ["mistral", "mistral-7b", "quick"],
      "context_window": 32768,
      "max_output_tokens": 8192,
      "supports_extended_thinking": false,
      "supports_json_mode": true,
      "supports_function_calling": true,
      "description": "Mistral 7B - Efficient model for quick queries",
      "intelligence_score": 10
    }
  ]
}
